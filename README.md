# Property Address Classifier

A machine learning classifier to categorize property addresses into predefined categories: flat, houseorplot, landparcel, commercial unit, and others.

## ğŸ“ Project Structure

```
property-classifier/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Original datasets
â”‚   â””â”€â”€ processed/           # Processed datasets
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb        # Exploratory Data Analysis
â”‚   â””â”€â”€ 02_modeling.ipynb    # Model training and evaluation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py            # Training script
â”‚   â””â”€â”€ predict.py          # Prediction script
â”œâ”€â”€ best_model/             # Saved model artifacts
â”‚   â”œâ”€â”€ classifier.pkl
â”‚   â”œâ”€â”€ vectorizer.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”œâ”€â”€ results/                # Evaluation results and plots
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ approach.txt           # Detailed methodology
â””â”€â”€ README.md              # This file
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Place Data

Put your datasets in the `data/raw/` folder:
- `train.csv`
- `validation.csv`

### 3. Train Model

```bash
python src/train.py
```

This will:
- Load and preprocess the data
- Train an XGBoost classifier
- Evaluate on validation set
- Save the model to `best_model/`

### 4. Make Predictions

**Single prediction:**
```bash
python src/predict.py "Flat 101, Tower A, Green Valley Apartments"
```

**Interactive mode:**
```bash
python src/predict.py
```

## ğŸ“Š Model Performance

**Validation Results:**
- Accuracy: 89.78%
- Macro F1 Score: 0.8823
- Weighted F1 Score: 0.8988

See `results/` folder for detailed classification reports and confusion matrices.

## ğŸ”§ Technical Details

**Features:**
- TF-IDF vectorization with n-grams (1-3)
- 5000 maximum features
- Min document frequency: 2

**Model:**
- XGBoost Classifier
- 200 estimators
- Max depth: 6
- Learning rate: 0.1

**Preprocessing:**
- Lowercase conversion
- Unicode normalization
- N-gram extraction (unigrams, bigrams, trigrams)

## ğŸ“ Notebooks

Explore the notebooks for detailed analysis:
1. `01_eda.ipynb` - Data exploration and visualization
2. `02_modeling.ipynb` - Model comparison and selection

## ğŸ¤ Author

Vipul Pawar

## ğŸ“„ License

This project is for educational/assignment purposes. 
