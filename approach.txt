PROPERTY ADDRESS CLASSIFICATION - DETAILED APPROACH
================================================================

1. PROBLEM UNDERSTANDING
================================================================
Objective: Classify property addresses into 5 predefined categories
Categories: flat, houseorplot, landparcel, commercial unit, others
Input: Raw text strings (property addresses)
Output: Single category label per address

Key Challenges Identified:
- Text data is short and unstructured
- Potential class imbalance
- Addresses may contain abbreviations and variations
- Keywords overlap between categories (e.g., "plot" vs "house plot")

2. EXPLORATORY DATA ANALYSIS (EDA)
================================================================
Dataset Overview:
- Training samples: 8,936 samples
- Validation samples: 2,681 samples
- No missing values detected

Class Distribution (Validation Set):
- flat: 36.2% (970 samples)
- houseorplot: 29.9% (802 samples)
- others: 13.4% (359 samples)
- commercial unit: 10.8% (290 samples)
- landparcel: 9.7% (260 samples)

Key Observations:
- Average address length: Varies from short (10-20 characters) to long (100+ characters)
- Common keywords identified: flat, apartment, plot, house, shop, office, land, tower, society
- Numeric patterns: floor numbers, area measurements (sq ft, acres), plot numbers
- Class imbalance: Moderate imbalance, with 'flat' being most common and 'landparcel' least common

Text Characteristics:
- Short text (typically 5-15 words)
- Contains location information (street, area, city)
- Property type indicators (flat, villa, plot, etc.)
- Numeric information (plot numbers, floor numbers, areas)

3. DATA PREPROCESSING
================================================================
Text Cleaning Steps:
a) Lowercasing: Convert all text to lowercase for consistency
b) Unicode normalization: Handle special characters and accents
c) Whitespace handling: Normalize multiple spaces

Feature Engineering Decision:
- Chose TF-IDF over simple Count Vectorization
  Reason: TF-IDF weighs important terms while reducing common words
  
- N-gram range: (1, 3)
  Reason: Captures phrases like "commercial plot", "apartment flat"
  
- Max features: 5000
  Reason: Balance between information retention and computational efficiency
  
- Min document frequency: 2
  Reason: Remove extremely rare terms that may cause overfitting

Why NOT heavy preprocessing:
- No stemming/lemmatization: Words like "flat" vs "plot" are crucial
- No stop word removal: Words like "on", "at" provide context
- Preserve numbers: Floor numbers and areas are important features

4. MODELING APPROACH
================================================================
Philosophy: Start simple, iterate to complex

Models Evaluated:
a) Logistic Regression (Baseline)
   - Simple, interpretable
   - Fast training
   - Good for text classification
   - Used as performance benchmark

b) Random Forest
   - Ensemble method
   - Handles non-linear relationships
   - Feature importance insights

c) XGBoost (Selected as Best)
   - Gradient boosting algorithm
   - Excellent performance on structured data
   - Handles class imbalance well
   - Robust to overfitting with proper tuning

d) LightGBM
   - Fast training alternative to XGBoost
   - Memory efficient

Best Model Selection Criteria:
- Primary: Macro F1 Score (handles class imbalance)
- Secondary: Overall accuracy
- Tertiary: Per-class F1 scores (ensure no category is neglected)

Final Model: XGBoost Classifier
Hyperparameters:
- n_estimators: 200 (sufficient trees without overfitting)
- max_depth: 6 (control complexity)
- learning_rate: 0.1 (standard value)
- subsample: 0.8 (reduce overfitting)
- colsample_bytree: 0.8 (feature randomization)
- random_state: 42 (reproducibility)

Why XGBoost won:
- Best macro F1 score on validation set
- Consistent per-class performance
- Handles imbalanced classes effectively with built-in class weighting
- Fast inference time

5. MODEL EVALUATION
================================================================
Validation Performance:
- Accuracy: 89.78%
- Macro F1 Score: 0.8823
- Weighted F1 Score: 0.8988

Per-Class Performance:
- commercial unit: Precision 0.97, Recall 0.90, F1 0.94 (290 samples)
- flat: Precision 0.96, Recall 0.93, F1 0.94 (970 samples)
- houseorplot: Precision 0.88, Recall 0.90, F1 0.89 (802 samples)
- landparcel: Precision 0.82, Recall 0.83, F1 0.83 (260 samples)
- others: Precision 0.78, Recall 0.85, F1 0.81 (359 samples)

Confusion Matrix Analysis:
- Most accurate predictions: commercial unit (F1: 0.94) and flat (F1: 0.94)
- Lowest performance: others (F1: 0.81) due to high diversity in this category
- Common misclassifications: 'others' category confused with specific types
- Reason: The 'others' category contains diverse property types that may share keywords with other categories

6. ERROR ANALYSIS
================================================================
Common Errors:
1. 'others' category misclassification
   - The diverse nature of 'others' makes it challenging
   - Items in 'others' may contain keywords like "plot", "house", "shop"
   - Total misclassifications: 274 out of 2,681 (10.22% error rate)

2. Landparcel vs Houseorplot confusion
   - Both categories may contain the keyword "plot"
   - Context differentiation (e.g., "agricultural land" vs "house plot") is crucial
   
Potential Improvements Tried:
- TF-IDF with n-grams (1-3): Captures phrase context better than unigrams
- Feature limit (5000 features): Balance between coverage and overfitting
- XGBoost class weighting: Helps with imbalanced classes

7. FINAL MODEL TRAINING
================================================================
Strategy: Train on full training data, evaluate on validation data
Reason: Maximize learning while maintaining unbiased evaluation

Model Artifacts Saved:
1. classifier.pkl - Trained XGBoost model (200 estimators)
2. vectorizer.pkl - TF-IDF vectorizer with fitted vocabulary (5000 features)
3. label_encoder.pkl - Category label encoder (5 classes)

Training Metrics:
- Training samples used: 8,936
- Validation samples: 2,681
- Training time: ~1-2 minutes on standard CPU
- Model size: ~2-3 MB total for all artifacts

8. REPRODUCIBILITY
================================================================
Ensuring Reproducible Results:
- Fixed random seed: 42
- Documented dependencies: requirements.txt
- Version-controlled code
- Clear training pipeline: src/train.py

Environment:
- Python version: 3.12
- Key libraries: scikit-learn, xgboost, pandas, numpy, matplotlib, seaborn
- All versions specified in requirements.txt

To Reproduce Results:
1. Install dependencies: pip install -r requirements.txt
2. Place data in data/raw/ (train.csv, validation.csv)
3. Run: python src/train.py
4. Models saved to best_model/
5. Expected output: Accuracy ~89.78%, Macro F1 ~0.88

9. INFERENCE & DEPLOYMENT
================================================================
Prediction Pipeline:
1. Load saved artifacts (model, vectorizer, encoder)
2. Transform input text using saved vectorizer
3. Predict using trained model
4. Decode prediction using label encoder

Usage:
- Command line: python src/predict.py "address text"
- Programmatic: Import functions from src/predict.py

10. LIMITATIONS & FUTURE WORK
================================================================
Current Limitations:
- Performance depends on training data quality
- May struggle with very unique/rare address formats
- No handling of typos or misspellings

Potential Improvements:
1. Deep Learning: Try BERT-based models for better semantic understanding
2. Data Augmentation: Synthetic address generation for minority classes
3. Feature Engineering: Add geographic features, property size indicators
4. Ensemble: Combine multiple models for robustness
5. Active Learning: Identify uncertain predictions for manual review

11. CONCLUSION
================================================================
Achieved strong classification performance using classical ML approach.
XGBoost with TF-IDF features provides a good balance of:
- Performance (Accuracy: 89.78%, Macro F1: 0.8823)
- Interpretability (feature importance from TF-IDF weights)
- Speed (fast training ~1-2 min and inference <1 sec)
- Reliability (robust to overfitting with proper hyperparameters)

The approach is:
✓ Reproducible (fixed seeds, documented pipeline)
✓ Efficient (trains in minutes)
✓ Practical (easy to deploy and maintain)
✓ Scalable (can handle large datasets)

Clean code structure and comprehensive documentation ensure easy handoff
and future improvements. The model performs well across all 5 categories,
with particularly strong results on 'flat' and 'commercial unit' classes. 
